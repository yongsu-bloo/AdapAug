{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from FastAutoAugment.train import GroupAugloader\n",
    "from FastAutoAugment.data import get_dataloaders, GrAugCIFAR10, CutoutDefault\n",
    "from FastAutoAugment.group_search import assign_group\n",
    "from FastAutoAugment.archive import arsaug_policy, autoaug_policy, autoaug_paper_cifar10, fa_reduced_cifar10, fa_reduced_svhn, fa_resnet50_rimagenet\n",
    "from theconf import Config as C, ConfigArgumentParser\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cifar10\"\n",
    "batch = 128\n",
    "dataroot = \"/home/server32/data/\"\n",
    "gr_assign = assign_group\n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.get()[\"cutout\"] = 16\n",
    "C.get()[\"aug\"] = \\\n",
    "{0: [[['TranslateX', 0.8933767594939269, 0.09389941707439498],\n",
    "   ['Equalize', 0.009283253282199254, 0.6216709279401148]],\n",
    "  [['TranslateX', 0.6042254125178238, 0.3840147802903179],\n",
    "   ['Invert', 0.5884490988202267, 0.26983244239417226]],\n",
    "  [['TranslateX', 0.86623214046742, 0.8015893993849521],\n",
    "   ['Cutout', 0.7629023447855925, 0.18040604440693134]],\n",
    "  [['Color', 0.3242635884647428, 0.8193831710695015],\n",
    "   ['AutoContrast', 0.8617900583601097, 0.2745968792879573]],\n",
    "  [['Cutout', 0.9932170309667162, 0.34739437256963557],\n",
    "   ['Posterize', 0.22013736848753707, 0.6423520078623738]]],\n",
    " 1: [[['ShearX', 0.9527555981799529, 0.840939180847609],\n",
    "   ['Brightness', 0.8812351461652247, 0.08476267857828268]],\n",
    "  [['Rotate', 0.2329661175045321, 0.37779148571576426],\n",
    "   ['TranslateY', 0.5042632755940204, 0.45960105920394156]],\n",
    "  [['Solarize', 0.5026188423517557, 0.6115728014024047],\n",
    "   ['ShearY', 0.3390709029909095, 0.002670085542884504]],\n",
    "  [['Cutout', 0.9991400014995132, 0.8739501611807547],\n",
    "   ['Contrast', 0.7952676665284365, 0.8408743613281001]],\n",
    "  [['Equalize', 0.011156446032402956, 0.13099359833583812],\n",
    "   ['Color', 0.43931113219589335, 0.6656400172139114]]],\n",
    " 2: [[['TranslateX', 0.6513948638994308, 0.6204299285398741],\n",
    "   ['Posterize', 0.7842262934822425, 0.25273070431283734]],\n",
    "  [['ShearY', 0.5609290367869623, 0.9452655885485695],\n",
    "   ['AutoContrast', 0.003634851336694944, 0.5115370485649638]],\n",
    "  [['Contrast', 0.0536986696863798, 0.997987299785687],\n",
    "   ['Cutout', 0.9333367903585464, 0.5098100423108692]],\n",
    "  [['Posterize', 0.5047403532237664, 0.8196327208059964],\n",
    "   ['Color', 0.46892732660093384, 0.4726497928422181]]],\n",
    " 3: [[['AutoContrast', 0.7213610218628191, 0.8416505099325328],\n",
    "   ['Rotate', 0.3682722275983766, 0.4179430092062895]],\n",
    "  [['Posterize', 0.079407408927398, 0.42541337413692293],\n",
    "   ['Contrast', 0.46058986564574006, 0.5817370708138572]],\n",
    "  [['Contrast', 0.7549878468501052, 0.4429642761204333],\n",
    "   ['Posterize', 0.6097943846630738, 0.41517079787104294]],\n",
    "  [['Cutout', 0.6737586712335524, 0.29603717863325374],\n",
    "   ['Posterize', 0.5305135986372213, 0.28136589567182224]],\n",
    "  [['Sharpness', 0.7334435795732214, 0.7550440511925695],\n",
    "   ['AutoContrast', 0.2499262684273169, 0.5822370638832948]]],\n",
    " 4: [[['Brightness', 0.25197963676329305, 0.5993017712343321],\n",
    "   ['TranslateY', 0.6276663840325515, 0.17444942645475542]],\n",
    "  [['Sharpness', 0.2501497210502566, 0.9994546724708385],\n",
    "   ['Contrast', 0.1678019343332606, 0.804693027679855]],\n",
    "  [['Equalize', 0.53438204404003, 0.22042762708232622],\n",
    "   ['AutoContrast', 0.6228907795771712, 0.9983253108022203]],\n",
    "  [['ShearY', 0.730964431113039, 0.500783309172612],\n",
    "   ['Rotate', 0.28839704924929926, 0.8669441267961313]],\n",
    "  [['TranslateY', 0.05479562529503221, 0.7442538413000629],\n",
    "   ['AutoContrast', 0.31896164940398547, 0.9264790385929341]]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-28 00:34:57,757] [Fast AutoAugment] [DEBUG] group augmentation provided.\n"
     ]
    }
   ],
   "source": [
    "dataloaders1 = get_dataloaders(dataset, batch, dataroot, split=0., split_idx=0, gr_assign=gr_assign)\n",
    "trainsampler1, trainloader1, validloader1, testloader1 = dataloaders1\n",
    "trainloader1 = GroupAugloader(trainloader1, gr_assign, C.get()[\"aug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "transform_train.transforms.append(CutoutDefault(16))\n",
    "total_trainset = GrAugCIFAR10(root=dataroot, gr_assign=gr_assign, gr_policies=C.get()[\"aug\"], train=True, download=False, transform=transform_train)\n",
    "train_sampler = None\n",
    "trainloader3 = torch.utils.data.DataLoader(\n",
    "        total_trainset, batch_size=batch, shuffle=True if train_sampler is None else False, num_workers=8, pin_memory=True,\n",
    "        sampler=train_sampler, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-28 00:34:59,376] [Fast AutoAugment] [DEBUG] augmentation provided.\n"
     ]
    }
   ],
   "source": [
    "C.get()[\"aug\"] = fa_reduced_cifar10()\n",
    "dataloaders2 = get_dataloaders(dataset, batch, dataroot, split=0., split_idx=0, gr_assign=None)\n",
    "trainsampler2, trainloader2, validloader2, testloader2 = dataloaders2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.504937171936035\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image2, label2 in trainloader2:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.220066785812378\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image1, label1 in trainloader1:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.020648717880249\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image3, label3 in trainloader3:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "save_image(image1, \"tmp1.png\")\n",
    "save_image(image2, \"tmp2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.654066801071167\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image2, label2 in trainloader2.dataset:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5268869400024414\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image1, label1 in trainloader1.dataloader.dataset:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.589488983154297\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for image2, label2 in trainloader3.dataset:\n",
    "    pass\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
